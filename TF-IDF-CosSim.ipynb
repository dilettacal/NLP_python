{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hauptquelle: \n",
    "https://sites.temple.edu/tudsc/2017/03/30/measuring-similarity-between-texts-in-python/\n",
    "\n",
    "### Zusätzliche Quelle(n):\n",
    "\n",
    "http://blog.christianperone.com/2011/10/machine-learning-text-feature-extraction-tf-idf-part-ii/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "import heapq\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from lxml.html import html_parser\n",
    "from spacy.lang.de import German\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "stopwords = stopwords.words(\"german\")\n",
    "stopwords.append(\"dass\")\n",
    "\n",
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['das rote auto hält an der roten ampel. das rote auto fährt zu schnell.', 'das schwarze auto wurde rot eingefärbt, weil die farbe rot lebendiger wirkt', 'das schwarze mofa fährt an der grünen ampel durch, hält aber am roten schild nicht und wird vom roten auto angefahren', 'morgen scheint die sonne und wir fahren ans meer']\n"
     ]
    }
   ],
   "source": [
    "CORPUS = [\n",
    "\"Das rote Auto hält an der roten Ampel. Das rote Auto fährt zu schnell.\", \n",
    "\"Das schwarze Auto wurde rot eingefärbt, weil die Farbe rot lebendiger wirkt\",\n",
    "\"Das schwarze Mofa fährt an der grünen Ampel durch, hält aber am roten Schild nicht und wird vom roten Auto angefahren\",\n",
    "\"Morgen scheint die Sonne und wir fahren ans Meer\"\n",
    "]\n",
    "\n",
    "CORPUS = [text.lower() for text in CORPUS]\n",
    "print(CORPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['der', 'rote', 'auto', 'halten', 'an', 'der', 'rot', 'ampel', 'der', 'rote', 'schwarze', 'auto', 'fahren', 'zu', 'schnellen', 'der', 'schwarze', 'mofa', 'sein', 'langsam']\n"
     ]
    }
   ],
   "source": [
    "satz = \"Das rote Auto hält an der roten Ampel. Das rote, schwarze Auto fährt zu schnell. Das schwarze Mofa ist langsam\"\n",
    "satz = satz.lower()\n",
    "sent = nlp(satz)\n",
    "lemmas = [word.lemma_ for word in sent if not word.is_punct]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatisierung der Adjektive und Adverbe klappt gar nicht:\n",
    "\n",
    "- rote \n",
    "- schwarze \n",
    "\n",
    "sollten auf ihr Lemmas zurückgezogen werden, nämlich \"rot\" und \"schwarz\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORPUS = [\n",
    "\"Das rot Auto hält an der roten Ampel\", \n",
    "\"Das schwarze Auto wurde rot eingefärbt\",\n",
    "\"Das schwarze Mofa fährt an der grünen Ampel durch\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = CORPUS.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer mit Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_.lower().translate(remove_punct_dict) for token in doc if not token.is_punct or not token.like_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wortfrequenz in einem Dokumen mit CountVectorizer (Uni- und Bigramme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = 1\n",
    "stop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_vectorizer = CountVectorizer(tokenizer=get_tokens, stop_words=stopwords, ngram_range=(start,stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x22 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vectorizer.fit_transform(CORPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rote': 15, 'auto': 4, 'halten': 9, 'rot': 14, 'ampel': 1, '': 0, 'fahren': 6, 'schnellen': 18, 'schwarze': 19, 'einfärben': 5, 'farbe': 7, 'lebendig': 10, 'wirken': 21, 'mofa': 12, 'grün': 8, 'schild': 17, 'anfahren': 2, 'morgen': 13, 'scheinen': 16, 'sonne': 20, 'ans': 3, 'meer': 11}\n",
      "\n",
      "Anzahl der N-Gramme:  22\n"
     ]
    }
   ],
   "source": [
    "print(token_vectorizer.vocabulary_)\n",
    "print(\"\\nAnzahl der N-Gramme: \", len(token_vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_matrix = token_vectorizer.transform(CORPUS).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 0 0 2 0 1 0 0 1 0 0 0 0 1 2 0 0 1 0 0 0]\n",
      " [1 0 0 0 1 1 0 1 0 0 1 0 0 0 2 0 0 0 0 1 0 1]\n",
      " [1 1 1 0 1 0 1 0 1 1 0 0 1 0 2 0 0 1 0 1 0 0]\n",
      " [0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(tf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.shape #(3 = Dokumente, 43 = Wörter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berechnung des IDF und Umwandlung des Ergebnisses zu einer TF-IDF-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liefert als Ergebnis einen Vektor, dessen Kompomenten der IDF-Wert für jedes Wort im Dictionary darstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF- Score für die Wörter im Corpus: ´\n",
      " [ 1.22314355  1.51082562  1.91629073  1.91629073  1.22314355  1.91629073\n",
      "  1.22314355  1.91629073  1.91629073  1.51082562  1.91629073  1.91629073\n",
      "  1.91629073  1.91629073  1.22314355  1.91629073  1.91629073  1.91629073\n",
      "  1.91629073  1.51082562  1.91629073  1.91629073]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidfTran = TfidfTransformer(norm=\"l2\")\n",
    "tfidfTran.fit(tf_matrix)\n",
    "print(\"IDF- Score für die Wörter im Corpus: ´\\n\", tfidfTran.idf_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF-Score für Wörter, die nur in 1 Dokument vorkommen: 1.6931471805599454\n",
      "IDF-Score für Wörter, die in 2 Dokumenten vorkommen: 1.2876820724517808\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def idf(n,df):\n",
    "    result = math.log((n+1.0)/(df+1.0)) + 1\n",
    "    return result\n",
    "\n",
    "anzahl_doc = 3\n",
    "print (\"IDF-Score für Wörter, die nur in 1 Dokument vorkommen: \" + str(idf(anzahl_doc,1)))#1x \n",
    "print (\"IDF-Score für Wörter, die in 2 Dokumenten vorkommen: \" + str(idf(anzahl_doc,2)))#2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Matrix\n",
    "\n",
    "Die transform-Methode multipliziert die tf-Matrix (4 x 41) mit der diagonalen idf-Matrix (41 x 41 mit dem idf-Wert für jeden Begriff auf der Hauptdiagonalen) und teilt die tf-idf durch die euklidische Norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.39743237  0.24545402  0.          0.          0.39743237  0.\n",
      "   0.19871618  0.          0.          0.24545402  0.          0.          0.\n",
      "   0.          0.19871618  0.6226546   0.          0.          0.3113273\n",
      "   0.          0.          0.        ]\n",
      " [ 0.24011956  0.          0.          0.          0.24011956  0.37619368\n",
      "   0.          0.37619368  0.          0.          0.37619368  0.          0.\n",
      "   0.          0.48023911  0.          0.          0.          0.\n",
      "   0.29659542  0.          0.37619368]\n",
      " [ 0.21619279  0.26704111  0.33870779  0.          0.21619279  0.\n",
      "   0.21619279  0.          0.33870779  0.26704111  0.          0.\n",
      "   0.33870779  0.          0.43238559  0.          0.          0.33870779\n",
      "   0.          0.26704111  0.          0.        ]\n",
      " [ 0.          0.          0.          0.43003652  0.          0.\n",
      "   0.27448674  0.          0.          0.          0.          0.43003652\n",
      "   0.          0.43003652  0.          0.          0.43003652  0.          0.\n",
      "   0.          0.43003652  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = tfidfTran.transform(tf_matrix)\n",
    "print (tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity - paarweise\n",
    "\n",
    "Die im letzten Schritt erhaltene Matrix wird mit ihrer transponierten Matrix multipliziert. Das Ergebnis ist die Ähnlichkeitsmatrix. Man bemerkt, dass die ersten 3 Dokumente miteinander ähnlicher sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos_similarity_matrix = (tfidf_matrix * tfidf_matrix.T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.28629385  0.43181968  0.05454496]\n",
      " [ 0.28629385  1.          0.39067588  0.        ]\n",
      " [ 0.43181968  0.39067588  1.          0.05934205]\n",
      " [ 0.05454496  0.          0.05934205  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cos_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine-Similarity mit sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "\n",
    "A_sparse = sparse.csr_matrix(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.28629385  0.43181968  0.05454496]\n",
      " [ 0.28629385  1.          0.39067588  0.        ]\n",
      " [ 0.43181968  0.39067588  1.          0.05934205]\n",
      " [ 0.05454496  0.          0.05934205  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#print(A_sparse)\n",
    "\n",
    "similarities = cosine_similarity(A_sparse)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF-Vectorizer\n",
    "\n",
    "Kombination vom TFidfVectorizer und CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "TfidfVec = TfidfVectorizer(tokenizer=get_tokens, stop_words=stopwords, ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_similarity(textlist):\n",
    "    tfidf = TfidfVec.fit_transform(textlist)\n",
    "    return (tfidf * tfidf.T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.13562957,  0.26402917,  0.02719766],\n",
       "       [ 0.13562957,  1.        ,  0.18141068,  0.        ],\n",
       "       [ 0.26402917,  0.18141068,  1.        ,  0.02900303],\n",
       "       [ 0.02719766,  0.        ,  0.02900303,  1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_similarity(CORPUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
